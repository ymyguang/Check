import datetime
import urllib.parse
from datetime import datetime as da
import time
from math import ceil
import feedback
import ddddocr
import requests
from bs4 import BeautifulSoup


targetQQ = 708227196
targetQQ = str(targetQQ)

set_name = set()
maxPage = 99
qq_dict = {
    "æ›¹éª": 3137136096,
    "éƒ­æ¥ ": 2690681751,
    "ææ˜‚": 1340170910,
    "ææ™¨": 591487622,
    "ææ¨Š": 3029198839,
    "åˆ˜å½ª": 2096304869,
    "ç½—ç¦": 2502013244,
    "ç‹é‘«": 2248278179,
    "å´å«": 1473908028,
    "å¼ ç¨³": 1548720908,
    "èµµä¼Ÿ": 2392965199,
    "è”¡æ€ç¦": 1656909554,
    "æ£æ˜Ÿå®‡": 2086798102,
    "é«˜ä¸–è±ª": 498661819,
    "éƒæ¢¦ç•…": 1208067561,
    "åº·å…´æ—º": 2315143636,
    "æä½³æ—": 1306791767,
    "ææ±Ÿæ¥ ": 1009740561,
    "æå¯æ¬£": 1092896132,
    "æå°šæ’": 1332250851,
    "æå…†æ—": 2697951507,
    "åˆ˜æ˜ä¸€": 1351244826,
    "åˆ˜å–„å®": 1395896975,
    "åˆ˜æ—­è¾‰": 775373008,
    "å•å¤©ä¹": 747920501,
    "è‹ä¸–è¶…": 292301843,
    "ç‹æ¹œè£•": 835017638,
    "è¾›å®‡èˆª": 953725247,
    "é‚¢æ¢“é˜³": 2209906415,
    "å¾æ™“æ°": 2817605916,
    "å¾é›ªå½¬": 2417933635,
    "æ¨ç¿”å®‡": 1950381153,
    "æ¨å®‡å“²": 2212607441,
    "å®‡æ–‡å¯è±ª": 1625290298,
    "ç« ä¼ å–œ": 2811165455,
    "å‘¨è¶…": 1000000000
}

header = {
    'Upgrade-Insecure-Requests': '1',
    'DNT': '1',
    'Content-Type': 'application/x-www-form-urlencoded',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
    'Referer': 'http://xscfw.hebust.edu.cn/evaluate/verifyCode?d=1636955535211',
    'Accept-Encoding': 'gzip, deflate',
    'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7'
}


# è·å–cookieå’ŒéªŒè¯ç 
def tryLogin():
    r = requests.get('http://xscfw.hebust.edu.cn/evaluate/verifyCode', stream=True)
    cookie = str(r.headers['Set-Cookie']).split(" ")[0]
    header['Cookie'] = cookie

    ocr = ddddocr.DdddOcr()
    res = ocr.classification(r.content)
    print("cookie:{}    verify:{}".format(cookie, res))
    r = requests.post("http://xscfw.hebust.edu.cn/evaluate/evaluate", headers=header,
                      data="username=xxxyhaolei&password=Haolei2021l19.&verifyCode=" + urllib.parse.quote(res))


# ä½¿cookieç”Ÿæ•ˆ (ç™»é™†)
def login():
    tryLogin()
    # ç™»é™†å¤±è´¥ï¼Œä¸€ç›´é‡å¤
    while not isOk():
        tryLogin()


def getUrl():
    url = "http://xscfw.hebust.edu.cn/evaluate/survey/surveyStuList?id="
    a = datetime.datetime(2021, 11, 12)
    b = datetime.datetime.now()
    cc = (b - a).days
    listName = 712 + cc
    url += str(listName)
    return url


def getId():
    c = requests.get("http://xscfw.hebust.edu.cn/evaluate/survey/surveyList", headers=header).text
    soup = BeautifulSoup(c, 'html.parser')
    now = da.now()
    current_time = now.strftime("%Yå¹´%mæœˆ%dæ—¥å¥åº·æ—¥æŠ¥")
    for tr in soup.findAll('tbody')[0].findAll('tr'):
        res = tr.a
        if current_time == res['title']:
            Lid = res['href']
            print(res['title'], "->", Lid)
            return 'http://xscfw.hebust.edu.cn/evaluate/survey/' + Lid


# ç™»é™†æˆåŠŸåï¼ˆcookieç”Ÿæ•ˆï¼‰è·å–åŸå§‹ä¿¡æ¯
def getInfo(page):
    # åˆå§‹åŒ–å‚æ•°
    global maxPage
    # æ„é€ è¯·æ±‚
    params = {
        "typeCX": 0,  # æœªå®Œæˆ0ï¼Œå·²å®Œæˆ1
        "pageNo": page,
        "classCX": "è½¯ä»¶L194"  # ç­çº§å·
    }
    c = requests.post(url=getId(), params=params, headers=header).text

    # è·å–maxPageæ•°æ®
    index = str(c).find("maxPage")
    if index == -1:  # æ— ä¿¡æ¯
        print("å…¨éƒ¨å¡«æŠ¥å®Œæˆ")
        maxPage = 0
    else:
        maxPage = int(c[index + 10])
    return c


def isOk():
    params = {
        "typeCX": 0,
        "pageNo": 1,
        "classCX": "è½¯ä»¶L194"
    }
    c = requests.post(url=getUrl(), params=params, headers=header).text
    # æ£€æŸ¥cookie
    if str(c).find("é‡æ–°") != -1 or str(c).find("æ­£ç¡®çš„ç”¨æˆ·å") != -1:
        print("ç™»é™†å¤±è´¥")
        return False
    print("ç™»é™†æˆåŠŸ")
    return True


# å¤„ç†ä¿¡æ¯
def process(index):
    target = getInfo(index)
    try:
        soup = BeautifulSoup(target, 'html.parser')
        if soup.tbody is None:
            return
        t = soup.tbody.get_text()
        tt = str(t).split("æœªå®Œæˆ")
        tt.pop()

        for i in tt:
            sin = i.split("\n")[-6]
            set_name.add(sin)
            print(sin)
    except():
        pass


def generateMess():
    pageNum = 8  # atçš„æ€»ä¸ªæ•°
    f = 0
    if len(set_name) == pageNum:
        return
    message = "å®å®å®ï¼Œèµ¶ç´§å¡«ä½“æ¸©ğŸ“£ğŸ“£ğŸ“£ \n"
    totalPage = str(ceil(len(set_name) / pageNum))
    currentPage = 1
    for e in set_name:
        f += 1  # è®°å½•æœ¬æ¬¡æ¨é€atçš„ä¸ªæ•°
        message += e + " "
        message += " @at={}@ \n".format(qq_dict[e])
        if f % pageNum == 0:  # æ»¡è¶³ä¸€é¡µçš„ä¸ªæ•°ï¼Œå°±æ¨é€
            message += "\nğŸŒ»ğŸŒ»ã€ç¬¬{}é¡µï¼Œå…±{}é¡µã€‘ğŸŒ»ğŸŒ»".format(str(currentPage), totalPage)
            currentPage += 1
            feedback.feedback(message, "G", qq=targetQQ)
            message = 'å®å®å®ï¼Œèµ¶ç´§å¡«ä½“æ¸©ğŸ“£ğŸ“£ğŸ“£ \n'
            time.sleep(6)  # 5ç§’å†…ä¸èƒ½è¿ç»­æ¨é€
    if f % pageNum != 0:  # ä¸æ˜¯pageNumå€æ•°çš„æƒ…å†µ
        message += "\nğŸŒ»ğŸŒ»ã€ç¬¬{}é¡µï¼Œå…±{}é¡µã€‘ğŸŒ»ğŸŒ»".format(str(currentPage), totalPage)
        feedback.feedback(message, "G", qq=targetQQ)


if __name__ == '__main__':
    print("\n")
    print(da.now())
    print("------------------------------------------------")
    login()
    for i in range(1, 100):
        print("################################################")
        process(i)
        if i == maxPage or maxPage == 0:
            break
    generateMess()
    print("------------------------------------------------")

    # i = 0
    # for e in qq_dict:
    #     i += 1
    #     if i > 13:
    #         break
    #     else:
    #         set_name.add(e)
    # print(len(set_name))
    # print(set_name)
    # generateMess()
